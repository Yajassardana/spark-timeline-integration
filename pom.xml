<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one or more
  ~ contributor license agreements.  See the NOTICE file distributed with
  ~ this work for additional information regarding copyright ownership.
  ~ The ASF licenses this file to You under the Apache License, Version 2.0
  ~ (the "License"); you may not use this file except in compliance with
  ~ the License.  You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>com.hortonworks</groupId>
  <artifactId>spark-timeline-integration</artifactId>
  <version>0.1-SNAPSHOT</version>
  <packaging>pom</packaging>

  <licenses>
    <license>
      <name>Apache 2.0 License</name>
      <url>http://www.apache.org/licenses/LICENSE-2.0.html</url>
      <distribution>repo</distribution>
    </license>
  </licenses>

  <properties>
    <!--language versions -->
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>


    <java.version>1.8</java.version>
    <java.version>1.7</java.version>
    <scala.binary.version>2.10</scala.binary.version>
    <scala.version>2.10.5</scala.version>
    <scala.version.tools>${scala.binary.version}</scala.version.tools>


    <hadoop.version>2.7.1</hadoop.version>
    <spark.version>1.6.0</spark.version>

    <!--1.7.4 == hadoop; 1.7.7 == spark -->
    <avro.version>1.7.4</avro.version>
    <avro.mapred.classifier>hadoop2</avro.mapred.classifier>
    <codahale.metrics.version>3.1.2</codahale.metrics.version>
    <flume.version>1.6.0</flume.version>
    <junit.version>4.11</junit.version>
    <log4j.version>1.2.17</log4j.version>
    <scalatest.version>2.2.6</scalatest.version>
    <slf4j.version>1.7.10</slf4j.version>

    <!-- build config options-->
    <test.jvm.args>-Xmx1g -Xms256m</test.jvm.args>
    <test.exclude.tags />


    <!-- plugins-->


    <maven.compiler.plugin.version>3.1</maven.compiler.plugin.version>
    <hamcrest.version>1.3</hamcrest.version>
    <surefire.plugin.version>2.18.1</surefire.plugin.version>
    <scalacheck.version>1.11.3</scalacheck.version>
    <scalatest.plugin.version>1.0</scalatest.plugin.version>
    <alchim.scala-maven-plugin.version>3.2.2</alchim.scala-maven-plugin.version>

  </properties>

  <dependencyManagement>
    <dependencies>
      <dependency>
        <groupId>org.scala-lang</groupId>
        <artifactId>scala-library</artifactId>
        <version>${scala.version}</version>
      </dependency>
      <dependency>
        <groupId>org.scalacheck</groupId>
        <artifactId>scalacheck_${scala.version.tools}</artifactId>
        <version>${scalacheck.version}</version>
      </dependency>
      <dependency>
        <groupId>org.scalatest</groupId>
        <artifactId>scalatest_${scala.version.tools}</artifactId>
        <version>${scalatest.version}</version>
      </dependency>

      <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>${junit.version}</version>
      </dependency>
      <dependency>
        <groupId>org.hamcrest</groupId>
        <artifactId>hamcrest-core</artifactId>
        <version>${hamcrest.version}</version>
      </dependency>

      <dependency>
        <groupId>org.hamcrest</groupId>
        <artifactId>hamcrest-library</artifactId>
        <version>${hamcrest.version}</version>
        <scope>test</scope>
      </dependency>

      <!-- hadoop-client includes the following jars, so they do not need to be
    included separately:
    hadoop-common, hadoop-hdfs (client?), hadoop-mapreduce-client-app,
    hadoop-yarn-api, hadoop-mapreduce-client-core,
    hadoop-mapreduce-client-jobclient, and hadoop-annotations
  -->
      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>${hadoop.version}</version>
      </dependency>

      <!--
        Hadoop HDFS is pulled in to guarantee that any split to hadoop-hdfs-client doesn't
        break the build.
      -->
      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdfs</artifactId>
        <version>${hadoop.version}</version>
      </dependency>

      <!-- hadoop-minicluster includes the following test-jars, so they do not
        need to be included separately:
        hadoop-common, hadoop-hdfs, hadoop-yarn-server-tests,
        hadoop-mapreduce-client-jobclient
      -->
      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-minicluster</artifactId>
        <version>${hadoop.version}</version>
        <exclusions>
          <exclusion>
            <groupId>com.sun.jersey.jersey-test-framework</groupId>
            <artifactId>jersey-test-framework-grizzly2</artifactId>
          </exclusion>
          <exclusion>
            <groupId>net.java.dev.jets3t</groupId>
            <artifactId>jets3t</artifactId>
          </exclusion>
        </exclusions>
      </dependency>

      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-yarn-client</artifactId>
        <version>${hadoop.version}</version>
        <exclusions>
          <exclusion>
            <groupId>com.sun.jersey.jersey-test-framework</groupId>
            <artifactId>jersey-test-framework-grizzly2</artifactId>
          </exclusion>
        </exclusions>
      </dependency>

      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-yarn-registry</artifactId>
        <version>${hadoop.version}</version>
      </dependency>

      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-yarn-server-web-proxy</artifactId>
        <version>${hadoop.version}</version>
      </dependency>

      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-aws</artifactId>
        <version>${hadoop.version}</version>
      </dependency>

      <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-azure</artifactId>
        <version>${hadoop.version}</version>
      </dependency>


      <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-core_2.10</artifactId>
        <version>${spark.version}</version>
      </dependency>
      <dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-yarn_2.10</artifactId>
        <version>${spark.version}</version>
      </dependency>

    </dependencies>
  </dependencyManagement>


  <build>
<!--
    <sourceDirectory>src/main/scala</sourceDirectory>
    <testSourceDirectory>src/test/scala</testSourceDirectory>
-->
    <pluginManagement>

      <plugins>

        <plugin>
          <groupId>org.codehaus.mojo</groupId>
          <artifactId>build-helper-maven-plugin</artifactId>
          <executions>
            <execution>
              <id>add-source</id>
              <phase>generate-sources</phase>
              <goals>
                <goal>add-source</goal>
              </goals>
              <configuration>
                <sources>
                  <source>src/main/scala</source>
                </sources>
              </configuration>
            </execution>
            <execution>
              <id>add-test-source</id>
              <phase>generate-test-sources</phase>
              <goals>
                <goal>add-test-source</goal>
              </goals>
              <configuration>
                <sources>
                  <source>src/test/scala</source>
                </sources>
              </configuration>
            </execution>
          </executions>
        </plugin>

        <plugin>
          <groupId>net.alchim31.maven</groupId>
          <artifactId>scala-maven-plugin</artifactId>
          <version>${alchim.scala-maven-plugin.version}</version>
          <executions>
            <execution>
              <goals>
                <goal>compile</goal>
                <goal>testCompile</goal>
              </goals>
            </execution>
          </executions>

          <configuration>
            <recompileMode>incremental</recompileMode>
            <useZincServer>true</useZincServer>
            <args>
              <arg>-unchecked</arg>
              <arg>-deprecation</arg>
              <arg>-feature</arg>
            </args>
            <jvmArgs>
              <jvmArg>-Xms1024m</jvmArg>
              <jvmArg>-Xmx1024m</jvmArg>
              <jvmArg>-XX:PermSize=256m</jvmArg>
              <jvmArg>-XX:MaxPermSize=256m</jvmArg>
              <jvmArg>-XX:ReservedCodeCacheSize=256m</jvmArg>
            </jvmArgs>
            <javacArgs>
              <javacArg>-source</javacArg>
              <javacArg>${java.version}</javacArg>
              <javacArg>-target</javacArg>
              <javacArg>${java.version}</javacArg>
              <javacArg>-Xlint:all,-serial,-path</javacArg>
            </javacArgs>
          </configuration>
        </plugin>

        <!-- Surefire runs all Java tests -->
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-surefire-plugin</artifactId>
          <version>${surefire.plugin.version}</version>
          <!-- Note config is repeated in scalatest config -->
          <configuration>
            <includes>
              <include>**/Test*.java</include>
              <include>**/*Test.java</include>
              <include>**/*TestCase.java</include>
              <include>**/*Suite.java</include>
            </includes>
            <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
            <argLine>${test.jvm.args}</argLine>
            <environmentVariables>
            </environmentVariables>
            <systemProperties>
              <java.awt.headless>true</java.awt.headless>
              <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
            </systemProperties>
            <failIfNoTests>false</failIfNoTests>
            <excludedGroups>${test.exclude.tags}</excludedGroups>
          </configuration>
        </plugin>

        <!-- Scalatest runs all Scala tests -->
        <plugin>
          <groupId>org.scalatest</groupId>
          <artifactId>scalatest-maven-plugin</artifactId>
          <version>${scalatest.plugin.version}</version>
          <!-- Note config is repeated in surefire config -->
          <configuration>
            <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
            <junitxml>.</junitxml>
            <filereports>SparkTestSuite.txt</filereports>
            <argLine>${test.jvm.args}</argLine>
            <stderr />
            <environmentVariables>
            </environmentVariables>
            <systemProperties>
              <java.awt.headless>true</java.awt.headless>
              <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
            </systemProperties>
            <!--          <tagsToExclude>${test.exclude.tags}</tagsToExclude>-->
          </configuration>
          <executions>
            <execution>
              <id>test</id>
              <goals>
                <goal>test</goal>
              </goals>
            </execution>
          </executions>
        </plugin>

      </plugins>
    </pluginManagement>
  </build>

</project>
